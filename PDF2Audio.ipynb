{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrL_MhvI1xPn"
      },
      "source": [
        "# PDF to Audio Converter\n",
        "\n",
        "This code can be used to convert PDFs into audio podcasts, lectures, summaries, and more. It uses OpenAI's GPT models for text generation and text-to-speech conversion.\n",
        "\n",
        "Source: [https://github.com/lamm-mit/PDF2Audio](https://github.com/lamm-mit/PDF2Audio)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JrPccs_M1qZ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "444c18f9-1c55-4498-bddc-74eca9f9dbb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m527.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.8/292.8 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.6/375.6 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install loguru gradio promptic pydantic pypdf tenacity openai -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "nEduHdSD1fE-",
        "outputId": "2bbeee24-2439-4e72-9d0d-1a7580f8ffa7",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://533d91b2945fbb9ffd.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://533d91b2945fbb9ffd.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title\n",
        "import concurrent.futures as cf\n",
        "import glob\n",
        "import io\n",
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "from tempfile import NamedTemporaryFile\n",
        "from typing import List, Literal\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "from loguru import logger\n",
        "from openai import OpenAI\n",
        "from promptic import llm\n",
        "from pydantic import BaseModel, ValidationError\n",
        "from pypdf import PdfReader\n",
        "from tenacity import retry, retry_if_exception_type\n",
        "\n",
        "import re\n",
        "\n",
        "def read_readme():\n",
        "    readme_path = Path(\"README.md\")\n",
        "    if readme_path.exists():\n",
        "        with open(readme_path, \"r\") as file:\n",
        "            content = file.read()\n",
        "            # Use regex to remove metadata enclosed in -- ... --\n",
        "            content = re.sub(r'--.*?--', '', content, flags=re.DOTALL)\n",
        "            return content\n",
        "    else:\n",
        "        return \"README.md not found. Please check the repository for more information.\"\n",
        "\n",
        "# Define multiple sets of instruction templates\n",
        "INSTRUCTION_TEMPLATES = {\n",
        "################# PODCAST ##################\n",
        "    \"podcast\": {\n",
        "        \"intro\": \"\"\"Your task is to take the input text provided and turn it into an lively, engaging, informative podcast dialogue, in the style of NPR. The input text may be messy or unstructured, as it could come from a variety of sources like PDFs or web pages.\n",
        "\n",
        "Don't worry about the formatting issues or any irrelevant information; your goal is to extract the key points, identify definitions, and interesting facts that could be discussed in a podcast.\n",
        "\n",
        "Define all terms used carefully for a broad audience of listeners.\n",
        "\"\"\",\n",
        "        \"text_instructions\": \"First, carefully read through the input text and identify the main topics, key points, and any interesting facts or anecdotes. Think about how you could present this information in a fun, engaging way that would be suitable for a high quality presentation.\",\n",
        "        \"scratch_pad\": \"\"\"Brainstorm creative ways to discuss the main topics and key points you identified in the input text. Consider using analogies, examples, storytelling techniques, or hypothetical scenarios to make the content more relatable and engaging for listeners.\n",
        "\n",
        "Keep in mind that your podcast should be accessible to a general audience, so avoid using too much jargon or assuming prior knowledge of the topic. If necessary, think of ways to briefly explain any complex concepts in simple terms.\n",
        "\n",
        "Use your imagination to fill in any gaps in the input text or to come up with thought-provoking questions that could be explored in the podcast. The goal is to create an informative and entertaining dialogue, so feel free to be creative in your approach.\n",
        "\n",
        "Define all terms used clearly and spend effort to explain the background.\n",
        "\n",
        "Write your brainstorming ideas and a rough outline for the podcast dialogue here. Be sure to note the key insights and takeaways you want to reiterate at the end.\n",
        "\n",
        "Make sure to make it fun and exciting.\n",
        "\"\"\",\n",
        "        \"prelude\": \"\"\"Now that you have brainstormed ideas and created a rough outline, it's time to write the actual podcast dialogue. Aim for a natural, conversational flow between the host and any guest speakers. Incorporate the best ideas from your brainstorming session and make sure to explain any complex topics in an easy-to-understand way.\n",
        "\"\"\",\n",
        "        \"dialog\": \"\"\"Write a very long, engaging, informative podcast dialogue here, based on the key points and creative ideas you came up with during the brainstorming session. Use a conversational tone and include any necessary context or explanations to make the content accessible to a general audience.\n",
        "\n",
        "Never use made-up names for the hosts and guests, but make it an engaging and immersive experience for listeners. Do not include any bracketed placeholders like [Host] or [Guest]. Design your output to be read aloud -- it will be directly converted into audio.\n",
        "\n",
        "Make the dialogue as long and detailed as possible, while still staying on topic and maintaining an engaging flow. Aim to use your full output capacity to create the longest podcast episode you can, while still communicating the key information from the input text in an entertaining way.\n",
        "\n",
        "At the end of the dialogue, have the host and guest speakers naturally summarize the main insights and takeaways from their discussion. This should flow organically from the conversation, reiterating the key points in a casual, conversational manner. Avoid making it sound like an obvious recap - the goal is to reinforce the central ideas one last time before signing off.\n",
        "\n",
        "The podcast should have around 20000 words.\n",
        "\"\"\",\n",
        "    },\n",
        "################# MATERIAL DISCOVERY SUMMARY ##################\n",
        "    \"SciAgents material discovery summary\": {\n",
        "        \"intro\": \"\"\"Your task is to take the input text provided and turn it into a lively, engaging conversation between a professor and a student in a panel discussion that describes a new material. The professor acts like Richard Feynman, but you never mention the name.\n",
        "\n",
        "The input text is the result of a design developed by SciAgents, an AI tool for scientific discovery that has come up with a detailed materials design.\n",
        "\n",
        "Don't worry about the formatting issues or any irrelevant information; your goal is to extract the key points, identify definitions, and interesting facts that could be discussed in a podcast.\n",
        "\n",
        "Define all terms used carefully for a broad audience of listeners.\n",
        "\"\"\",\n",
        "        \"text_instructions\": \"First, carefully read through the input text and identify the main topics, key points, and any interesting facts or anecdotes. Think about how you could present this information in a fun, engaging way that would be suitable for a high quality presentation.\",\n",
        "        \"scratch_pad\": \"\"\"Brainstorm creative ways to discuss the main topics and key points you identified in the material design summary, especially paying attention to design features developed by SciAgents. Consider using analogies, examples, storytelling techniques, or hypothetical scenarios to make the content more relatable and engaging for listeners.\n",
        "\n",
        "Keep in mind that your description should be accessible to a general audience, so avoid using too much jargon or assuming prior knowledge of the topic. If necessary, think of ways to briefly explain any complex concepts in simple terms.\n",
        "\n",
        "Use your imagination to fill in any gaps in the input text or to come up with thought-provoking questions that could be explored in the podcast. The goal is to create an informative and entertaining dialogue, so feel free to be creative in your approach.\n",
        "\n",
        "Define all terms used clearly and spend effort to explain the background.\n",
        "\n",
        "Write your brainstorming ideas and a rough outline for the podcast dialogue here. Be sure to note the key insights and takeaways you want to reiterate at the end.\n",
        "\n",
        "Make sure to make it fun and exciting. You never refer to the podcast, you just discuss the discovery and you focus on the new material design only.\n",
        "\"\"\",\n",
        "        \"prelude\": \"\"\"Now that you have brainstormed ideas and created a rough outline, it's time to write the actual podcast dialogue. Aim for a natural, conversational flow between the host and any guest speakers. Incorporate the best ideas from your brainstorming session and make sure to explain any complex topics in an easy-to-understand way.\n",
        "\"\"\",\n",
        "        \"dialog\": \"\"\"Write a very long, engaging, informative dialogue here, based on the key points and creative ideas you came up with during the brainstorming session. The presentation must focus on the novel aspects of the material design, behavior, and all related aspects.\n",
        "\n",
        "Use a conversational tone and include any necessary context or explanations to make the content accessible to a general audience, but make it detailed, logical, and technical so that it has all necessary aspects for listeners to understand the material and its unexpected properties.\n",
        "\n",
        "Remember, this describes a design developed by SciAgents, and this must be explicitly stated for the listeners.\n",
        "\n",
        "Never use made-up names for the hosts and guests, but make it an engaging and immersive experience for listeners. Do not include any bracketed placeholders like [Host] or [Guest]. Design your output to be read aloud -- it will be directly converted into audio.\n",
        "\n",
        "Make the dialogue as long and detailed as possible with great scientific depth, while still staying on topic and maintaining an engaging flow. Aim to use your full output capacity to create the longest podcast episode you can, while still communicating the key information from the input text in an entertaining way.\n",
        "\n",
        "At the end of the dialogue, have the host and guest speakers naturally summarize the main insights and takeaways from their discussion. This should flow organically from the conversation, reiterating the key points in a casual, conversational manner. Avoid making it sound like an obvious recap - the goal is to reinforce the central ideas one last time before signing off.\n",
        "\n",
        "The conversation should have around 20000 words.\n",
        "\"\"\"\n",
        "    },\n",
        "################# LECTURE ##################\n",
        "    \"lecture\": {\n",
        "        \"intro\": \"\"\"You are Professor Richard Feynman. Your task is to develop a script for a lecture. You never mention your name.\n",
        "\n",
        "The material covered in the lecture is based on the provided text.\n",
        "\n",
        "Don't worry about the formatting issues or any irrelevant information; your goal is to extract the key points, identify definitions, and interesting facts that need to be covered in the lecture.\n",
        "\n",
        "Define all terms used carefully for a broad audience of students.\n",
        "\"\"\",\n",
        "        \"text_instructions\": \"First, carefully read through the input text and identify the main topics, key points, and any interesting facts or anecdotes. Think about how you could present this information in a fun, engaging way that would be suitable for a high quality presentation.\",\n",
        "        \"scratch_pad\": \"\"\"\n",
        "Brainstorm creative ways to discuss the main topics and key points you identified in the input text. Consider using analogies, examples, storytelling techniques, or hypothetical scenarios to make the content more relatable and engaging for listeners.\n",
        "\n",
        "Keep in mind that your lecture should be accessible to a general audience, so avoid using too much jargon or assuming prior knowledge of the topic. If necessary, think of ways to briefly explain any complex concepts in simple terms.\n",
        "\n",
        "Use your imagination to fill in any gaps in the input text or to come up with thought-provoking questions that could be explored in the podcast. The goal is to create an informative and entertaining dialogue, so feel free to be creative in your approach.\n",
        "\n",
        "Define all terms used clearly and spend effort to explain the background.\n",
        "\n",
        "Write your brainstorming ideas and a rough outline for the lecture here. Be sure to note the key insights and takeaways you want to reiterate at the end.\n",
        "\n",
        "Make sure to make it fun and exciting.\n",
        "\"\"\",\n",
        "        \"prelude\": \"\"\"Now that you have brainstormed ideas and created a rough outline, it's time to write the actual podcast dialogue. Aim for a natural, conversational flow between the host and any guest speakers. Incorporate the best ideas from your brainstorming session and make sure to explain any complex topics in an easy-to-understand way.\n",
        "\"\"\",\n",
        "        \"dialog\": \"\"\"Write a very long, engaging, informative script here, based on the key points and creative ideas you came up with during the brainstorming session. Use a conversational tone and include any necessary context or explanations to make the content accessible to the students.\n",
        "\n",
        "Include clear definitions and terms, and examples.\n",
        "\n",
        "Do not include any bracketed placeholders like [Host] or [Guest]. Design your output to be read aloud -- it will be directly converted into audio.\n",
        "\n",
        "There is only one speaker, you, the professor. Stay on topic and maintaining an engaging flow. Aim to use your full output capacity to create the longest lecture you can, while still communicating the key information from the input text in an engaging way.\n",
        "\n",
        "At the end of the lecture, naturally summarize the main insights and takeaways from the lecture. This should flow organically from the conversation, reiterating the key points in a casual, conversational manner.\n",
        "\n",
        "Avoid making it sound like an obvious recap - the goal is to reinforce the central ideas covered in this lecture one last time before class is over.\n",
        "\n",
        "The lecture should have around 20000 words.\n",
        "\"\"\",\n",
        "    },\n",
        "################# SUMMARY ##################\n",
        "        \"summary\": {\n",
        "        \"intro\": \"\"\"Your task is to develop a summary of a paper. You never mention your name.\n",
        "\n",
        "Don't worry about the formatting issues or any irrelevant information; your goal is to extract the key points, identify definitions, and interesting facts that need to be summarized.\n",
        "\n",
        "Define all terms used carefully for a broad audience.\n",
        "\"\"\",\n",
        "        \"text_instructions\": \"First, carefully read through the input text and identify the main topics, key points, and key facts. Think about how you could present this information in an accurate summary.\",\n",
        "        \"scratch_pad\": \"\"\"Brainstorm creative ways to present the main topics and key points you identified in the input text. Consider using analogies, examples, or hypothetical scenarios to make the content more relatable and engaging for listeners.\n",
        "\n",
        "Keep in mind that your summary should be accessible to a general audience, so avoid using too much jargon or assuming prior knowledge of the topic. If necessary, think of ways to briefly explain any complex concepts in simple terms. Define all terms used clearly and spend effort to explain the background.\n",
        "\n",
        "Write your brainstorming ideas and a rough outline for the summary here. Be sure to note the key insights and takeaways you want to reiterate at the end.\n",
        "\n",
        "Make sure to make it engaging and exciting.\n",
        "\"\"\",\n",
        "        \"prelude\": \"\"\"Now that you have brainstormed ideas and created a rough outline, it is time to write the actual summary. Aim for a natural, conversational flow between the host and any guest speakers. Incorporate the best ideas from your brainstorming session and make sure to explain any complex topics in an easy-to-understand way.\n",
        "\"\"\",\n",
        "        \"dialog\": \"\"\"Write a a script here, based on the key points and creative ideas you came up with during the brainstorming session. Use a conversational tone and include any necessary context or explanations to make the content accessible to the the audience.\n",
        "\n",
        "Start your script by stating that this is a summary, referencing the title or headings in the input text. If the input text has no title, come up with a succinct summary of what is covered to open.\n",
        "\n",
        "Include clear definitions and terms, and examples, of all key issues.\n",
        "\n",
        "Do not include any bracketed placeholders like [Host] or [Guest]. Design your output to be read aloud -- it will be directly converted into audio.\n",
        "\n",
        "There is only one speaker, you. Stay on topic and maintaining an engaging flow.\n",
        "\n",
        "Naturally summarize the main insights and takeaways from the summary. This should flow organically from the conversation, reiterating the key points in a casual, conversational manner.\n",
        "\n",
        "The summary should have around 1024 words.\n",
        "\"\"\",\n",
        "    },\n",
        "################# SHORT SUMMARY ##################\n",
        "        \"short summary\": {\n",
        "        \"intro\": \"\"\"Your task is to develop a summary of a paper. You never mention your name.\n",
        "\n",
        "Don't worry about the formatting issues or any irrelevant information; your goal is to extract the key points, identify definitions, and interesting facts that need to be summarized.\n",
        "\n",
        "Define all terms used carefully for a broad audience.\n",
        "\"\"\",\n",
        "        \"text_instructions\": \"First, carefully read through the input text and identify the main topics, key points, and key facts. Think about how you could present this information in an accurate summary.\",\n",
        "        \"scratch_pad\": \"\"\"Brainstorm creative ways to present the main topics and key points you identified in the input text. Consider using analogies, examples, or hypothetical scenarios to make the content more relatable and engaging for listeners.\n",
        "\n",
        "Keep in mind that your summary should be accessible to a general audience, so avoid using too much jargon or assuming prior knowledge of the topic. If necessary, think of ways to briefly explain any complex concepts in simple terms. Define all terms used clearly and spend effort to explain the background.\n",
        "\n",
        "Write your brainstorming ideas and a rough outline for the summary here. Be sure to note the key insights and takeaways you want to reiterate at the end.\n",
        "\n",
        "Make sure to make it engaging and exciting.\n",
        "\"\"\",\n",
        "        \"prelude\": \"\"\"Now that you have brainstormed ideas and created a rough outline, it is time to write the actual summary. Aim for a natural, conversational flow between the host and any guest speakers. Incorporate the best ideas from your brainstorming session and make sure to explain any complex topics in an easy-to-understand way.\n",
        "\"\"\",\n",
        "        \"dialog\": \"\"\"Write a a script here, based on the key points and creative ideas you came up with during the brainstorming session. Keep it concise, and use a conversational tone and include any necessary context or explanations to make the content accessible to the the audience.\n",
        "\n",
        "Start your script by stating that this is a summary, referencing the title or headings in the input text. If the input text has no title, come up with a succinct summary of what is covered to open.\n",
        "\n",
        "Include clear definitions and terms, and examples, of all key issues.\n",
        "\n",
        "Do not include any bracketed placeholders like [Host] or [Guest]. Design your output to be read aloud -- it will be directly converted into audio.\n",
        "\n",
        "There is only one speaker, you. Stay on topic and maintaining an engaging flow.\n",
        "\n",
        "Naturally summarize the main insights and takeaways from the short summary. This should flow organically from the conversation, reiterating the key points in a casual, conversational manner.\n",
        "\n",
        "The summary should have around 256 words.\n",
        "\"\"\",\n",
        "    },\n",
        "}\n",
        "\n",
        "# Function to update instruction fields based on template selection\n",
        "def update_instructions(template):\n",
        "    return (\n",
        "        INSTRUCTION_TEMPLATES[template][\"intro\"],\n",
        "        INSTRUCTION_TEMPLATES[template][\"text_instructions\"],\n",
        "        INSTRUCTION_TEMPLATES[template][\"scratch_pad\"],\n",
        "        INSTRUCTION_TEMPLATES[template][\"prelude\"],\n",
        "        INSTRUCTION_TEMPLATES[template][\"dialog\"]\n",
        "           )\n",
        "\n",
        "import concurrent.futures as cf\n",
        "import glob\n",
        "import io\n",
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "from tempfile import NamedTemporaryFile\n",
        "from typing import List, Literal\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "from loguru import logger\n",
        "from openai import OpenAI\n",
        "from promptic import llm\n",
        "from pydantic import BaseModel, ValidationError\n",
        "from pypdf import PdfReader\n",
        "from tenacity import retry, retry_if_exception_type\n",
        "\n",
        "# Define standard values\n",
        "STANDARD_TEXT_MODELS = [\n",
        "    \"o1-preview-2024-09-12\",\n",
        "    \"o1-preview\",\n",
        "    \"gpt-4o-2024-08-06\",\n",
        "    \"gpt-4o-mini\",\n",
        "    \"o1-mini-2024-09-12\",\n",
        "    \"o1-mini\",\n",
        "    \"chatgpt-4o-latest\",\n",
        "    \"gpt-4-turbo\",\n",
        "    \"openai/custom_model\",\n",
        "]\n",
        "\n",
        "STANDARD_AUDIO_MODELS = [\n",
        "    \"tts-1\",\n",
        "    \"tts-1-hd\",\n",
        "]\n",
        "\n",
        "STANDARD_VOICES = [\n",
        "    \"alloy\",\n",
        "    \"echo\",\n",
        "    \"fable\",\n",
        "    \"onyx\",\n",
        "    \"nova\",\n",
        "    \"shimmer\",\n",
        "]\n",
        "\n",
        "class DialogueItem(BaseModel):\n",
        "    text: str\n",
        "    speaker: Literal[\"speaker-1\", \"speaker-2\"]\n",
        "\n",
        "class Dialogue(BaseModel):\n",
        "    scratchpad: str\n",
        "    dialogue: List[DialogueItem]\n",
        "\n",
        "def get_mp3(text: str, voice: str, audio_model: str, api_key: str = None) -> bytes:\n",
        "    client = OpenAI(\n",
        "        api_key=api_key or os.getenv(\"OPENAI_API_KEY\"),\n",
        "    )\n",
        "\n",
        "    with client.audio.speech.with_streaming_response.create(\n",
        "        model=audio_model,\n",
        "        voice=voice,\n",
        "        input=text,\n",
        "    ) as response:\n",
        "        with io.BytesIO() as file:\n",
        "            for chunk in response.iter_bytes():\n",
        "                file.write(chunk)\n",
        "            return file.getvalue()\n",
        "\n",
        "\n",
        "from functools import wraps\n",
        "\n",
        "def conditional_llm(model, api_base=None, api_key=None):\n",
        "    \"\"\"\n",
        "    Conditionally apply the @llm decorator based on the api_base parameter.\n",
        "    If api_base is provided, it applies the @llm decorator with api_base.\n",
        "    Otherwise, it applies the @llm decorator without api_base.\n",
        "    \"\"\"\n",
        "    def decorator(func):\n",
        "        if api_base:\n",
        "            return llm(model=model, api_base=api_base)(func)\n",
        "        else:\n",
        "            return llm(model=model, api_key=api_key)(func)\n",
        "    return decorator\n",
        "\n",
        "def generate_audio(\n",
        "    files: list,\n",
        "    openai_api_key: str = None,\n",
        "    text_model: str = \"o1-preview-2024-09-12\",\n",
        "    audio_model: str = \"tts-1\",\n",
        "    speaker_1_voice: str = \"alloy\",\n",
        "    speaker_2_voice: str = \"echo\",\n",
        "    api_base: str = None,\n",
        "    intro_instructions: str = '',\n",
        "    text_instructions: str = '',\n",
        "    scratch_pad_instructions: str = '',\n",
        "    prelude_dialog: str = '',\n",
        "    podcast_dialog_instructions: str = '',\n",
        "    edited_transcript: str = None,\n",
        "    user_feedback: str = None,\n",
        "    original_text: str = None,\n",
        "    debug = False,\n",
        ") -> tuple:\n",
        "    # Validate API Key\n",
        "    if not os.getenv(\"OPENAI_API_KEY\") and not openai_api_key:\n",
        "        raise gr.Error(\"OpenAI API key is required\")\n",
        "\n",
        "    combined_text = original_text or \"\"\n",
        "\n",
        "    # If there's no original text, extract it from the uploaded files\n",
        "    if not combined_text:\n",
        "        for file in files:\n",
        "            with Path(file).open(\"rb\") as f:\n",
        "                reader = PdfReader(f)\n",
        "                text = \"\\n\\n\".join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
        "                combined_text += text + \"\\n\\n\"\n",
        "\n",
        "    # Configure the LLM based on selected model and api_base\n",
        "    @retry(retry=retry_if_exception_type(ValidationError))\n",
        "    @conditional_llm(model=text_model, api_base=api_base, api_key=openai_api_key)\n",
        "    def generate_dialogue(text: str, intro_instructions: str, text_instructions: str, scratch_pad_instructions: str,\n",
        "                          prelude_dialog: str, podcast_dialog_instructions: str,\n",
        "                          edited_transcript: str = None, user_feedback: str = None, ) -> Dialogue:\n",
        "        \"\"\"\n",
        "        {intro_instructions}\n",
        "\n",
        "        Here is the original input text:\n",
        "\n",
        "        <input_text>\n",
        "        {text}\n",
        "        </input_text>\n",
        "\n",
        "        {text_instructions}\n",
        "\n",
        "        <scratchpad>\n",
        "        {scratch_pad_instructions}\n",
        "        </scratchpad>\n",
        "\n",
        "        {prelude_dialog}\n",
        "\n",
        "        <podcast_dialogue>\n",
        "        {podcast_dialog_instructions}\n",
        "        </podcast_dialogue>\n",
        "        {edited_transcript}{user_feedback}\n",
        "        \"\"\"\n",
        "\n",
        "    instruction_improve='Based on the original text, please generate an improved version of the dialogue by incorporating the edits, comments and feedback.'\n",
        "    edited_transcript_processed=\"\\nPreviously generated edited transcript, with specific edits and comments that I want you to carefully address:\\n\"+\"<edited_transcript>\\n\"+edited_transcript+\"</edited_transcript>\" if edited_transcript !=\"\" else \"\"\n",
        "    user_feedback_processed=\"\\nOverall user feedback:\\n\\n\"+user_feedback if user_feedback !=\"\" else \"\"\n",
        "\n",
        "    if edited_transcript_processed.strip()!='' or user_feedback_processed.strip()!='':\n",
        "        user_feedback_processed=\"<requested_improvements>\"+user_feedback_processed+\"\\n\\n\"+instruction_improve+\"</requested_improvements>\"\n",
        "\n",
        "    if debug:\n",
        "        logger.info (edited_transcript_processed)\n",
        "        logger.info (user_feedback_processed)\n",
        "\n",
        "    # Generate the dialogue using the LLM\n",
        "    llm_output = generate_dialogue(\n",
        "        combined_text,\n",
        "        intro_instructions=intro_instructions,\n",
        "        text_instructions=text_instructions,\n",
        "        scratch_pad_instructions=scratch_pad_instructions,\n",
        "        prelude_dialog=prelude_dialog,\n",
        "        podcast_dialog_instructions=podcast_dialog_instructions,\n",
        "        edited_transcript=edited_transcript_processed,\n",
        "        user_feedback=user_feedback_processed\n",
        "    )\n",
        "\n",
        "    # Generate audio from the transcript\n",
        "    audio = b\"\"\n",
        "    transcript = \"\"\n",
        "    characters = 0\n",
        "\n",
        "    with cf.ThreadPoolExecutor() as executor:\n",
        "        futures = []\n",
        "        for line in llm_output.dialogue:\n",
        "            transcript_line = f\"{line.speaker}: {line.text}\"\n",
        "            voice = speaker_1_voice if line.speaker == \"speaker-1\" else speaker_2_voice\n",
        "            future = executor.submit(get_mp3, line.text, voice, audio_model, openai_api_key)\n",
        "            futures.append((future, transcript_line))\n",
        "            characters += len(line.text)\n",
        "\n",
        "        for future, transcript_line in futures:\n",
        "            audio_chunk = future.result()\n",
        "            audio += audio_chunk\n",
        "            transcript += transcript_line + \"\\n\\n\"\n",
        "\n",
        "    logger.info(f\"Generated {characters} characters of audio\")\n",
        "\n",
        "    temporary_directory = \"./gradio_cached_examples/tmp/\"\n",
        "    os.makedirs(temporary_directory, exist_ok=True)\n",
        "\n",
        "    # Use a temporary file -- Gradio's audio component doesn't work with raw bytes in Safari\n",
        "    temporary_file = NamedTemporaryFile(\n",
        "        dir=temporary_directory,\n",
        "        delete=False,\n",
        "        suffix=\".mp3\",\n",
        "    )\n",
        "    temporary_file.write(audio)\n",
        "    temporary_file.close()\n",
        "\n",
        "    # Delete any files in the temp directory that end with .mp3 and are over a day old\n",
        "    for file in glob.glob(f\"{temporary_directory}*.mp3\"):\n",
        "        if os.path.isfile(file) and time.time() - os.path.getmtime(file) > 24 * 60 * 60:\n",
        "            os.remove(file)\n",
        "\n",
        "    return temporary_file.name, transcript, combined_text\n",
        "\n",
        "def validate_and_generate_audio(*args):\n",
        "    files = args[0]\n",
        "    if not files:\n",
        "        return None, None, None, \"Please upload at least one PDF file before generating audio.\"\n",
        "    try:\n",
        "        audio_file, transcript, original_text = generate_audio(*args)\n",
        "        return audio_file, transcript, original_text, None  # Return None as the error when successful\n",
        "    except Exception as e:\n",
        "        # If an error occurs during generation, return None for the outputs and the error message\n",
        "        return None, None, None, str(e)\n",
        "\n",
        "def edit_and_regenerate(edited_transcript, user_feedback, *args):\n",
        "    # Replace the original transcript and feedback in the args with the new ones\n",
        "    #new_args = list(args)\n",
        "    #new_args[-2] = edited_transcript  # Update edited transcript\n",
        "    #new_args[-1] = user_feedback  # Update user feedback\n",
        "    return validate_and_generate_audio(*new_args)\n",
        "\n",
        "# New function to handle user feedback and regeneration\n",
        "def process_feedback_and_regenerate(feedback, *args):\n",
        "    # Add user feedback to the args\n",
        "    new_args = list(args)\n",
        "    new_args.append(feedback)  # Add user feedback as a new argument\n",
        "    return validate_and_generate_audio(*new_args)\n",
        "\n",
        "with gr.Blocks(title=\"PDF to Audio\", css=\"\"\"\n",
        "    #header {\n",
        "        display: flex;\n",
        "        align-items: center;\n",
        "        justify-content: space-between;\n",
        "        padding: 20px;\n",
        "        background-color: transparent;\n",
        "        border-bottom: 1px solid #ddd;\n",
        "    }\n",
        "    #title {\n",
        "        font-size: 24px;\n",
        "        margin: 0;\n",
        "    }\n",
        "    #logo_container {\n",
        "        width: 200px;\n",
        "        height: 200px;\n",
        "        display: flex;\n",
        "        justify-content: center;\n",
        "        align-items: center;\n",
        "    }\n",
        "    #logo_image {\n",
        "        max-width: 100%;\n",
        "        max-height: 100%;\n",
        "        object-fit: contain;\n",
        "    }\n",
        "    #main_container {\n",
        "        margin-top: 20px;\n",
        "    }\n",
        "\"\"\") as demo:\n",
        "\n",
        "    with gr.Row(elem_id=\"header\"):\n",
        "        with gr.Column(scale=4):\n",
        "            gr.Markdown(\"# Convert PDFs into an audio podcast, lecture, summary and others\\n\\nFirst, upload one or more PDFs, select options, then push Generate Audio.\\n\\nYou can also select a variety of custom option and direct the way the result is generated.\", elem_id=\"title\")\n",
        "        with gr.Column(scale=1):\n",
        "            gr.HTML('''\n",
        "                <div id=\"logo_container\">\n",
        "                    <img src=\"https://huggingface.co/spaces/lamm-mit/PDF2Audio/resolve/main/logo.png\" id=\"logo_image\" alt=\"Logo\">\n",
        "                </div>\n",
        "            ''')\n",
        "    #gr.Markdown(\"\")\n",
        "    submit_btn = gr.Button(\"Generate Audio\", elem_id=\"submit_btn\")\n",
        "\n",
        "    with gr.Row(elem_id=\"main_container\"):\n",
        "        with gr.Column(scale=2):\n",
        "            files = gr.Files(label=\"PDFs\", file_types=[\"pdf\"], )\n",
        "\n",
        "            openai_api_key = gr.Textbox(\n",
        "                label=\"OpenAI API Key\",\n",
        "                visible=True,  # Always show the API key field\n",
        "                placeholder=\"Enter your OpenAI API Key here...\",\n",
        "                type=\"password\"  # Hide the API key input\n",
        "            )\n",
        "            text_model = gr.Dropdown(\n",
        "                label=\"Text Generation Model\",\n",
        "                choices=STANDARD_TEXT_MODELS,\n",
        "                value=\"o1-preview-2024-09-12\", #\"gpt-4o-mini\",\n",
        "                info=\"Select the model to generate the dialogue text.\",\n",
        "            )\n",
        "            audio_model = gr.Dropdown(\n",
        "                label=\"Audio Generation Model\",\n",
        "                choices=STANDARD_AUDIO_MODELS,\n",
        "                value=\"tts-1\",\n",
        "                info=\"Select the model to generate the audio.\",\n",
        "            )\n",
        "            speaker_1_voice = gr.Dropdown(\n",
        "                label=\"Speaker 1 Voice\",\n",
        "                choices=STANDARD_VOICES,\n",
        "                value=\"alloy\",\n",
        "                info=\"Select the voice for Speaker 1.\",\n",
        "            )\n",
        "            speaker_2_voice = gr.Dropdown(\n",
        "                label=\"Speaker 2 Voice\",\n",
        "                choices=STANDARD_VOICES,\n",
        "                value=\"echo\",\n",
        "                info=\"Select the voice for Speaker 2.\",\n",
        "            )\n",
        "            api_base = gr.Textbox(\n",
        "                label=\"Custom API Base\",\n",
        "                placeholder=\"Enter custom API base URL if using a custom/local model...\",\n",
        "                info=\"If you are using a custom or local model, provide the API base URL here, e.g.: http://localhost:8080/v1 for llama.cpp REST server.\",\n",
        "            )\n",
        "\n",
        "        with gr.Column(scale=3):\n",
        "            template_dropdown = gr.Dropdown(\n",
        "                label=\"Instruction Template\",\n",
        "                choices=list(INSTRUCTION_TEMPLATES.keys()),\n",
        "                value=\"podcast\",\n",
        "                info=\"Select the instruction template to use. You can also edit any of the fields for more tailored results.\",\n",
        "            )\n",
        "            intro_instructions = gr.Textbox(\n",
        "                label=\"Intro Instructions\",\n",
        "                lines=10,\n",
        "                value=INSTRUCTION_TEMPLATES[\"podcast\"][\"intro\"],\n",
        "                info=\"Provide the introductory instructions for generating the dialogue.\",\n",
        "            )\n",
        "            text_instructions = gr.Textbox(\n",
        "                label=\"Standard Text Analysis Instructions\",\n",
        "                lines=10,\n",
        "                placeholder=\"Enter text analysis instructions...\",\n",
        "                value=INSTRUCTION_TEMPLATES[\"podcast\"][\"text_instructions\"],\n",
        "                info=\"Provide the instructions for analyzing the raw data and text.\",\n",
        "            )\n",
        "            scratch_pad_instructions = gr.Textbox(\n",
        "                label=\"Scratch Pad Instructions\",\n",
        "                lines=15,\n",
        "                value=INSTRUCTION_TEMPLATES[\"podcast\"][\"scratch_pad\"],\n",
        "                info=\"Provide the scratch pad instructions for brainstorming presentation/dialogue content.\",\n",
        "            )\n",
        "            prelude_dialog = gr.Textbox(\n",
        "                label=\"Prelude Dialog\",\n",
        "                lines=5,\n",
        "                value=INSTRUCTION_TEMPLATES[\"podcast\"][\"prelude\"],\n",
        "                info=\"Provide the prelude instructions before the presentation/dialogue is developed.\",\n",
        "            )\n",
        "            podcast_dialog_instructions = gr.Textbox(\n",
        "                label=\"Podcast Dialog Instructions\",\n",
        "                lines=20,\n",
        "                value=INSTRUCTION_TEMPLATES[\"podcast\"][\"dialog\"],\n",
        "                info=\"Provide the instructions for generating the presentation or podcast dialogue.\",\n",
        "            )\n",
        "\n",
        "    audio_output = gr.Audio(label=\"Audio\", format=\"mp3\")\n",
        "    transcript_output = gr.Textbox(label=\"Transcript\", lines=20, show_copy_button=True)\n",
        "    original_text_output = gr.Textbox(label=\"Original Text\", lines=10, visible=False)\n",
        "    error_output = gr.Textbox(visible=False)  # Hidden textbox to store error message\n",
        "\n",
        "    use_edited_transcript = gr.Checkbox(label=\"Use Edited Transcript (check if you want to make edits to the initially generated transcript)\", value=False)\n",
        "    edited_transcript = gr.Textbox(label=\"Edit Transcript Here. E.g., mark edits in the text with clear instructions. E.g., '[ADD DEFINITION OF MATERIOMICS]'.\", lines=20, visible=False,\n",
        "                                   show_copy_button=True, interactive=False)\n",
        "\n",
        "    user_feedback = gr.Textbox(label=\"Provide Feedback or Notes\", lines=10, #placeholder=\"Enter your feedback or notes here...\"\n",
        "                              )\n",
        "    regenerate_btn = gr.Button(\"Regenerate Audio with Edits and Feedback\")\n",
        "    # Function to update the interactive state of edited_transcript\n",
        "    def update_edit_box(checkbox_value):\n",
        "        return gr.update(interactive=checkbox_value, lines=20 if checkbox_value else 20, visible=True if checkbox_value else False)\n",
        "\n",
        "    # Update the interactive state of edited_transcript when the checkbox is toggled\n",
        "    use_edited_transcript.change(\n",
        "        fn=update_edit_box,\n",
        "        inputs=[use_edited_transcript],\n",
        "        outputs=[edited_transcript]\n",
        "    )\n",
        "    # Update instruction fields when template is changed\n",
        "    template_dropdown.change(\n",
        "        fn=update_instructions,\n",
        "        inputs=[template_dropdown],\n",
        "        outputs=[intro_instructions, text_instructions, scratch_pad_instructions, prelude_dialog, podcast_dialog_instructions]\n",
        "    )\n",
        "\n",
        "    submit_btn.click(\n",
        "        fn=validate_and_generate_audio,\n",
        "        inputs=[\n",
        "            files, openai_api_key, text_model, audio_model,\n",
        "            speaker_1_voice, speaker_2_voice, api_base,\n",
        "            intro_instructions, text_instructions, scratch_pad_instructions,\n",
        "            prelude_dialog, podcast_dialog_instructions,\n",
        "            edited_transcript,  # placeholder for edited_transcript\n",
        "            user_feedback,  # placeholder for user_feedback\n",
        "        ],\n",
        "        outputs=[audio_output, transcript_output, original_text_output, error_output]\n",
        "    ).then(\n",
        "        fn=lambda audio, transcript, original_text, error: (\n",
        "            transcript if transcript else \"\",\n",
        "            error if error else None\n",
        "        ),\n",
        "        inputs=[audio_output, transcript_output, original_text_output, error_output],\n",
        "        outputs=[edited_transcript, error_output]\n",
        "    ).then(\n",
        "        fn=lambda error: gr.Warning(error) if error else None,\n",
        "        inputs=[error_output],\n",
        "        outputs=[]\n",
        "    )\n",
        "\n",
        "    regenerate_btn.click(\n",
        "        fn=lambda use_edit, edit, *args: validate_and_generate_audio(\n",
        "            *args[:12],  # All inputs up to podcast_dialog_instructions\n",
        "            edit if use_edit else \"\",  # Use edited transcript if checkbox is checked, otherwise empty string\n",
        "            *args[12:]  # user_feedback and original_text_output\n",
        "        ),\n",
        "        inputs=[\n",
        "            use_edited_transcript, edited_transcript,\n",
        "            files, openai_api_key, text_model, audio_model,\n",
        "            speaker_1_voice, speaker_2_voice, api_base,\n",
        "            intro_instructions, text_instructions, scratch_pad_instructions,\n",
        "            prelude_dialog, podcast_dialog_instructions,\n",
        "            user_feedback, original_text_output\n",
        "        ],\n",
        "        outputs=[audio_output, transcript_output, original_text_output, error_output]\n",
        "    ).then(\n",
        "        fn=lambda audio, transcript, original_text, error: (\n",
        "            transcript if transcript else \"\",\n",
        "            error if error else None\n",
        "        ),\n",
        "        inputs=[audio_output, transcript_output, original_text_output, error_output],\n",
        "        outputs=[edited_transcript, error_output]\n",
        "    ).then(\n",
        "        fn=lambda error: gr.Warning(error) if error else None,\n",
        "        inputs=[error_output],\n",
        "        outputs=[]\n",
        "    )\n",
        "\n",
        "    # Add README content at the bottom\n",
        "    gr.Markdown(\"---\")  # Horizontal line to separate the interface from README\n",
        "    gr.Markdown(read_readme())\n",
        "\n",
        "# Enable queueing for better performance\n",
        "demo.queue(max_size=20, default_concurrency_limit=32)\n",
        "\n",
        "# Launch the Gradio app\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fvlp5EvQ2ApM"
      },
      "source": [
        "## Credits\n",
        "\n",
        "This project was inspired by and based on the code available at [https://github.com/knowsuchagency/pdf-to-podcast](https://github.com/knowsuchagency/pdf-to-podcast) and [https://github.com/knowsuchagency/promptic](https://github.com/knowsuchagency/promptic).\n",
        "\n",
        "```bibtex\n",
        "@article{ghafarollahi2024sciagentsautomatingscientificdiscovery,\n",
        "    title={SciAgents: Automating scientific discovery through multi-agent intelligent graph reasoning},\n",
        "    author={Alireza Ghafarollahi and Markus J. Buehler},\n",
        "    year={2024},\n",
        "    eprint={2409.05556},\n",
        "    archivePrefix={arXiv},\n",
        "    primaryClass={cs.AI},\n",
        "    url={https://arxiv.org/abs/2409.05556},\n",
        "}\n",
        "@article{buehler2024graphreasoning,\n",
        "    title={Accelerating Scientific Discovery with Generative Knowledge Extraction, Graph-Based Representation, and Multimodal Intelligent Graph Reasoning},\n",
        "    author={Markus J. Buehler},\n",
        "    journal={Machine Learning: Science and Technology},\n",
        "    year={2024},\n",
        "    url={http://iopscience.iop.org/article/10.1088/2632-2153/ad7228},\n",
        "}\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}